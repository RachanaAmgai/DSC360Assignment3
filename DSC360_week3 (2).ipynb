{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rachana Amgai\n",
    "### Assignment 3\n",
    "### 12/15/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlFo2KnWSXrf"
   },
   "source": [
    "###  here is the uploading PDF file from local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glr2jPaaSizM"
   },
   "source": [
    "I'm retrieving the file from the folder saved on my COMPUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "GPcg7NsUmtyT",
    "outputId": "3287904f-90ed-4d01-ca54-15840dbba9f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b74c6e4d-b68c-43c7-b1d6-4f13ca3b497b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b74c6e4d-b68c-43c7-b1d6-4f13ca3b497b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Week_3_No_Tables.pdf to Week_3_No_Tables (1).pdf\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXwm-0F0TP6n"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o80P0j9T3zE"
   },
   "source": [
    "### Here is the  List of files in my current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHr-MHF6T8yP"
   },
   "source": [
    "Now that my file is in my notebook, I have to specify the directory or path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGLCMMw0nhsJ",
    "outputId": "3da7011d-cb55-448c-9331-be095571f913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config', 'Week_3_No_Tables.pdf', 'sample_data']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njz6zu8brSiW",
    "outputId": "a91f00eb-388b-4afb-fcc1-1eb8da5e0844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_s7wU7XWmIA"
   },
   "source": [
    "### I am Opening and Printing the PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIieHCUpWpN7"
   },
   "source": [
    "After installing PyPDF2, a library that will help transfrom my pdf file, I use the library to open my file and \"print\" to see the text from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSwQJDvGoTHO",
    "outputId": "2aa1c82f-1fad-4d1d-c84a-2c753599a8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "Exercises  \n",
      "1. Create a simple PDF file without tables (you can use Microsoft Word to create a document and \n",
      "save it as a PDF file) and read the text using Python. Print the results.  \n",
      "2. Create a simple PDF file with tables (you can use Microsoft Word to create a docum ent and save \n",
      "it as a PDF file) and read the text using Python. Print the results.  \n",
      "3. Go through the Microsoft tutorial to create a form processing model using the Microsoft invoice \n",
      "samples. Do a “quick test” using the test invoice. Then, after reading abou t how you can \n",
      "incorporate your model in Power Automate, create a simple Power Automate flow that reads \n",
      "that test invoice and shows the data fields within it. (There may be a tutorial available from \n",
      "Microsoft that shows you how to do this.)  \n",
      "4. Assuming you  installed Tesseract, use pytesseract to read the Bowers text image found in the \n",
      "GitHub for Week 3 (week_3 \\data \\bowers.jpg). Then use spaCy to print out the tokens (the text, \n",
      "part of speech, and dependency).  \n",
      "For the Python assignments, you can submit Jup yter Notebooks or PDFs of your code (one for each \n",
      "exercise). If you submit .py files you need to also include a PDF or attachment of your results.  \n",
      "For the Power Automate assignment, share your completed flow with me (fneugebauer@bellevue.edu).  \n",
      "Don’t for get to work on your project – Milestone 2 is due next week.  \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "file_name = 'Week_3_No_Tables.pdf'\n",
    "\n",
    "\n",
    "with open(file_name, 'rb') as file:\n",
    "  reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "  # Print the text from each page\n",
    "  for page_num in range(len(reader.pages)):\n",
    "    page = reader.pages[page_num]\n",
    "    text = page.extract_text()\n",
    "    print(f\"Page {page_num+1}:\\n{text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seAumPSvsQBL"
   },
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVUGn9SHXaEc"
   },
   "source": [
    "I  have installed tabula-py to because the pdf has a table. It will convert the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSBRMa-Hqsm2",
    "outputId": "89f37037-b6d2-424b-89d8-4e8ebfa6460c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabula-py\n",
      "  Downloading tabula_py-2.9.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (2.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.26.4)\n",
      "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "Downloading tabula_py-2.9.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tabula-py\n",
      "Successfully installed tabula-py-2.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrBP6KKFXyjp"
   },
   "source": [
    "# Uploading the  PDF file from local machine or Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx2rHjxgcTHw"
   },
   "source": [
    "As before im importing the file from my folder saved on my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "ZC4QPsNIsATU",
    "outputId": "79fe1b7d-6d18-40e4-cb08-06dde503c245"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c64d5081-f404-4229-9724-c34c53c3c7ea\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c64d5081-f404-4229-9724-c34c53c3c7ea\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Week_3_With_Tables.pdf to Week_3_With_Tables.pdf\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FPIjvUAX_7O"
   },
   "source": [
    "# Extract the table from the uploaded PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kop_TE14YE5l"
   },
   "source": [
    "Im puting tabula to work by reading the information from the uploaded file with a table. I uploaded the file the same way I explained for problem 1. I used the print function to display the text from the pdf file with the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSOQ9V8otCIN",
    "outputId": "b6824994-5ba0-448d-80d4-3a3dcd17b1b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
      "WARNING:tabula.backend:No module named 'jpype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1:\n",
      "           X1    X2         X3    X4\n",
      "0  14.360550   Jun -11.072800  asia\n",
      "1   0.328324  July   4.601376  asia\n",
      "2   3.824882   Aug  17.351750  asia\n",
      "3  -6.201020   Aug   6.084073  asia\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "\n",
    "file_name = 'Week_3_With_Tables.pdf'\n",
    "\n",
    "tables = tabula.read_pdf(file_name, pages = 'all', multiple_tables=True)\n",
    "\n",
    "for idx, table in enumerate(tables):\n",
    "  print(f\"Table {idx+1}:\\n\", table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbhP1beIx9pz"
   },
   "source": [
    "# part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ziU5CrOZAkX"
   },
   "source": [
    "here are intalling tesseract and pytesseract to extract and format the text from the pdf image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1AvQLHruzhu",
    "outputId": "d2f92d3e-009f-4329-8262-2534b7b17291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
      "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
      "Need to get 4,816 kB of archives.\n",
      "After this operation, 15.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
      "Fetched 4,816 kB in 0s (17.3 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "(Reading database ... 123597 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install tesseract-ocr\n",
    "!pip install pytesseract\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BMJXUoTamyC"
   },
   "source": [
    "# Uploading PDF file from local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "7VraDrzOy-BV",
    "outputId": "9d36ae9a-f20e-49a4-dfb7-9b5588c733aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-456a6b9a-9a5c-4676-b601-e22cb069015a\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-456a6b9a-9a5c-4676-b601-e22cb069015a\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bowers.png to bowers.png\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soNwdxrfaxvl"
   },
   "source": [
    "# Perform OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXq_67HmbDZ9"
   },
   "source": [
    "Specifying the file that was uploaded in the cell above. I am using tesseract to pull the text from the pdf image and printing to display the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSOsMKHd1c00",
    "outputId": "09173e99-d037-43b7-ecf1-f777f1f10e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text:\n",
      "  \n",
      "\n",
      " \n",
      "\n",
      "The Life and Work of\n",
      "Fredson Bowers\n",
      "\n",
      "by\n",
      "G. THOMAS TANSELLE\n",
      "\n",
      " \n",
      "\n",
      "N EVERY FIELD OF ENDEAVOR THERE ARE A FEW FIGURES WHOSE AGCOM-\n",
      "plishment and influence cause them to be the symbols of their age;\n",
      "their careers and oeuvres become the touchstones by which the\n",
      "field is measured and its history told. In the related pursuits of\n",
      "\n",
      "analytical and descriptive bibliography, textual criticism, and scholarly\n",
      "editing, Fredson Bowers was such a figure, dominating the four decades\n",
      "after 1949, when his Principles of Bibliographical Description was pub-\n",
      "lished. By 1973 the period was already being called “the age of Bowers”:\n",
      "in that year Norman Sanders, writing the chapter on textual scholarship\n",
      "for Stanley Wells's Shakespeare: Select Bibliographies, gave this title to\n",
      "a section of his essay. For most people, it would be achievement enough\n",
      "to rise to such a position in a field as complex as Shakespearean textual\n",
      "studies; but Bowers played an equally important role in other areas.\n",
      "Editors of nineteenth-century American authors, for example, would\n",
      "also have to call the recent past “the age of Bowers,” as would the writers\n",
      "of descriptive bibliographies of authors and presses. His ubiquity in\n",
      "the broad field of bibliographical and textual study, his seemingly com-\n",
      "plete possession of it, distinguished him from his illustrious predeces-\n",
      "sors and made him the personification of bibliographical scholarship in\n",
      "his time.\n",
      "\n",
      "When in 1969 Bowers was awarded the Gold Medal of the Biblio-\n",
      "graphical Society in London, John Carter’s citation referred to the\n",
      "Principles as “majestic,” called Bowers’s current projects “formidable,”\n",
      "said that he had “imposed critical discipline” on the texts of several\n",
      "authors, described Studies in Bibliography as a “great and continuing\n",
      "achievement,” and included among his characteristics ‘uncompromising\n",
      "seriousness of purpose” and “professional intensity.” Bowers was not\n",
      "unaccustomed to such encomia, but he had also experienced his share of\n",
      "attacks: his scholarly positions were not universally popular, and he\n",
      "expressed them with an aggressiveness that almost seemed calculated to\n",
      "\n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Loading image\n",
    "image = Image.open('bowers.png')\n",
    "\n",
    "# Extracting text using tesseract\n",
    "text = pytesseract.image_to_string(image)\n",
    "print(\"Extracted text:\\n\", text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whEqORO6bmBo"
   },
   "source": [
    "# CLeaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFw8GqVpbo_b"
   },
   "outputs": [],
   "source": [
    "CLeaning the document by removing extra characters and printing to display the clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHBNdsp94JtZ",
    "outputId": "a28cd00a-c8d5-4578-a796-9c647bf3c0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean text:\n",
      "  \n",
      "\n",
      " \n",
      "\n",
      "The Life and Work of\n",
      "Fredson Bowers\n",
      "\n",
      "by\n",
      "G THOMAS TANSELLE\n",
      "\n",
      " \n",
      "\n",
      "N EVERY FIELD OF ENDEAVOR THERE ARE A FEW FIGURES WHOSE AGCOM\n",
      "plishment and influence cause them to be the symbols of their age\n",
      "their careers and oeuvres become the touchstones by which the\n",
      "field is measured and its history told In the related pursuits of\n",
      "\n",
      "analytical and descriptive bibliography textual criticism and scholarly\n",
      "editing Fredson Bowers was such a figure dominating the four decades\n",
      "after 1949 when his Principles of Bibliographical Description was pub\n",
      "lished By 1973 the period was already being called the age of Bowers\n",
      "in that year Norman Sanders writing the chapter on textual scholarship\n",
      "for Stanley Wellss Shakespeare Select Bibliographies gave this title to\n",
      "a section of his essay For most people it would be achievement enough\n",
      "to rise to such a position in a field as complex as Shakespearean textual\n",
      "studies but Bowers played an equally important role in other areas\n",
      "Editors of nineteenthcentury American authors for example would\n",
      "also have to call the recent past the age of Bowers as would the writers\n",
      "of descriptive bibliographies of authors and presses His ubiquity in\n",
      "the broad field of bibliographical and textual study his seemingly com\n",
      "plete possession of it distinguished him from his illustrious predeces\n",
      "sors and made him the personification of bibliographical scholarship in\n",
      "his time\n",
      "\n",
      "When in 1969 Bowers was awarded the Gold Medal of the Biblio\n",
      "graphical Society in London John Carters citation referred to the\n",
      "Principles as majestic called Bowerss current projects formidable\n",
      "said that he had imposed critical discipline on the texts of several\n",
      "authors described Studies in Bibliography as a great and continuing\n",
      "achievement and included among his characteristics uncompromising\n",
      "seriousness of purpose and professional intensity Bowers was not\n",
      "unaccustomed to such encomia but he had also experienced his share of\n",
      "attacks his scholarly positions were not universally popular and he\n",
      "expressed them with an aggressiveness that almost seemed calculated to\n",
      "\n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "print(\"Clean text:\\n\", clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT0Vlt8Sb8Ic"
   },
   "source": [
    "# Processing with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPBb4N1Hb_1-"
   },
   "source": [
    "Using spacy to create tokens from the cleaned text and printing to display the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0VoML2D3SM0",
    "outputId": "6fa5ef93-3145-4762-df57-7dffc6fc8146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  \n",
      "\n",
      " \n",
      "\n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: The, POS: DET, Dependency: det\n",
      "Token: Life, POS: PROPN, Dependency: nmod\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: Work, POS: PROPN, Dependency: conj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: Fredson, POS: PROPN, Dependency: compound\n",
      "Token: Bowers, POS: PROPN, Dependency: pobj\n",
      "Token: \n",
      "\n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: by, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: G, POS: PROPN, Dependency: compound\n",
      "Token: THOMAS, POS: PROPN, Dependency: compound\n",
      "Token: TANSELLE, POS: PROPN, Dependency: pobj\n",
      "Token: \n",
      "\n",
      " \n",
      "\n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: N, POS: PROPN, Dependency: appos\n",
      "Token: EVERY, POS: DET, Dependency: det\n",
      "Token: FIELD, POS: NOUN, Dependency: nsubj\n",
      "Token: OF, POS: ADP, Dependency: prep\n",
      "Token: ENDEAVOR, POS: PROPN, Dependency: pobj\n",
      "Token: THERE, POS: PRON, Dependency: nsubj\n",
      "Token: ARE, POS: AUX, Dependency: ROOT\n",
      "Token: A, POS: DET, Dependency: det\n",
      "Token: FEW, POS: ADJ, Dependency: amod\n",
      "Token: FIGURES, POS: NOUN, Dependency: nsubj\n",
      "Token: WHOSE, POS: PRON, Dependency: poss\n",
      "Token: AGCOM, POS: PROPN, Dependency: compound\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: plishment, POS: NOUN, Dependency: nsubj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: influence, POS: NOUN, Dependency: conj\n",
      "Token: cause, POS: VERB, Dependency: relcl\n",
      "Token: them, POS: PRON, Dependency: nsubj\n",
      "Token: to, POS: PART, Dependency: aux\n",
      "Token: be, POS: AUX, Dependency: ccomp\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: symbols, POS: NOUN, Dependency: attr\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: their, POS: PRON, Dependency: poss\n",
      "Token: age, POS: NOUN, Dependency: pobj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: their, POS: PRON, Dependency: poss\n",
      "Token: careers, POS: NOUN, Dependency: nsubj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: oeuvres, POS: NOUN, Dependency: conj\n",
      "Token: become, POS: VERB, Dependency: relcl\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: touchstones, POS: NOUN, Dependency: attr\n",
      "Token: by, POS: ADP, Dependency: prep\n",
      "Token: which, POS: PRON, Dependency: pobj\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: field, POS: NOUN, Dependency: nsubjpass\n",
      "Token: is, POS: AUX, Dependency: auxpass\n",
      "Token: measured, POS: VERB, Dependency: relcl\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: its, POS: PRON, Dependency: poss\n",
      "Token: history, POS: NOUN, Dependency: nsubj\n",
      "Token: told, POS: VERB, Dependency: conj\n",
      "Token: In, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: related, POS: VERB, Dependency: amod\n",
      "Token: pursuits, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: \n",
      "\n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: analytical, POS: ADJ, Dependency: amod\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: descriptive, POS: ADJ, Dependency: conj\n",
      "Token: bibliography, POS: NOUN, Dependency: nmod\n",
      "Token: textual, POS: ADJ, Dependency: amod\n",
      "Token: criticism, POS: NOUN, Dependency: pobj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: scholarly, POS: ADJ, Dependency: amod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: editing, POS: VERB, Dependency: xcomp\n",
      "Token: Fredson, POS: PROPN, Dependency: compound\n",
      "Token: Bowers, POS: PROPN, Dependency: dobj\n",
      "Token: was, POS: AUX, Dependency: ccomp\n",
      "Token: such, POS: DET, Dependency: predet\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: figure, POS: NOUN, Dependency: attr\n",
      "Token: dominating, POS: VERB, Dependency: acl\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: four, POS: NUM, Dependency: nummod\n",
      "Token: decades, POS: NOUN, Dependency: dobj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: after, POS: ADP, Dependency: prep\n",
      "Token: 1949, POS: NUM, Dependency: pobj\n",
      "Token: when, POS: SCONJ, Dependency: advmod\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: Principles, POS: PROPN, Dependency: nsubj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: Bibliographical, POS: PROPN, Dependency: compound\n",
      "Token: Description, POS: PROPN, Dependency: pobj\n",
      "Token: was, POS: AUX, Dependency: auxpass\n",
      "Token: pub, POS: AUX, Dependency: auxpass\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: lished, POS: VERB, Dependency: relcl\n",
      "Token: By, POS: ADP, Dependency: prep\n",
      "Token: 1973, POS: NUM, Dependency: pobj\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: period, POS: NOUN, Dependency: nsubjpass\n",
      "Token: was, POS: AUX, Dependency: aux\n",
      "Token: already, POS: ADV, Dependency: advmod\n",
      "Token: being, POS: AUX, Dependency: auxpass\n",
      "Token: called, POS: VERB, Dependency: acl\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: age, POS: NOUN, Dependency: oprd\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: Bowers, POS: PROPN, Dependency: pobj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: that, POS: DET, Dependency: det\n",
      "Token: year, POS: NOUN, Dependency: pobj\n",
      "Token: Norman, POS: PROPN, Dependency: compound\n",
      "Token: Sanders, POS: PROPN, Dependency: nsubj\n",
      "Token: writing, POS: VERB, Dependency: advcl\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: chapter, POS: NOUN, Dependency: dobj\n",
      "Token: on, POS: ADP, Dependency: prep\n",
      "Token: textual, POS: ADJ, Dependency: amod\n",
      "Token: scholarship, POS: NOUN, Dependency: pobj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: for, POS: ADP, Dependency: prep\n",
      "Token: Stanley, POS: PROPN, Dependency: compound\n",
      "Token: Wellss, POS: PROPN, Dependency: compound\n",
      "Token: Shakespeare, POS: PROPN, Dependency: compound\n",
      "Token: Select, POS: PROPN, Dependency: compound\n",
      "Token: Bibliographies, POS: PROPN, Dependency: nsubj\n",
      "Token: gave, POS: VERB, Dependency: conj\n",
      "Token: this, POS: DET, Dependency: det\n",
      "Token: title, POS: NOUN, Dependency: dobj\n",
      "Token: to, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: section, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: essay, POS: NOUN, Dependency: pobj\n",
      "Token: For, POS: ADP, Dependency: prep\n",
      "Token: most, POS: ADJ, Dependency: amod\n",
      "Token: people, POS: NOUN, Dependency: pobj\n",
      "Token: it, POS: PRON, Dependency: nsubj\n",
      "Token: would, POS: AUX, Dependency: aux\n",
      "Token: be, POS: AUX, Dependency: advcl\n",
      "Token: achievement, POS: NOUN, Dependency: attr\n",
      "Token: enough, POS: ADV, Dependency: advmod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: to, POS: PART, Dependency: aux\n",
      "Token: rise, POS: VERB, Dependency: xcomp\n",
      "Token: to, POS: ADP, Dependency: prep\n",
      "Token: such, POS: DET, Dependency: predet\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: position, POS: NOUN, Dependency: pobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: field, POS: NOUN, Dependency: pobj\n",
      "Token: as, POS: ADV, Dependency: advmod\n",
      "Token: complex, POS: ADJ, Dependency: amod\n",
      "Token: as, POS: ADP, Dependency: prep\n",
      "Token: Shakespearean, POS: ADJ, Dependency: amod\n",
      "Token: textual, POS: ADJ, Dependency: amod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: studies, POS: NOUN, Dependency: pobj\n",
      "Token: but, POS: CCONJ, Dependency: cc\n",
      "Token: Bowers, POS: PROPN, Dependency: nsubj\n",
      "Token: played, POS: VERB, Dependency: conj\n",
      "Token: an, POS: DET, Dependency: det\n",
      "Token: equally, POS: ADV, Dependency: advmod\n",
      "Token: important, POS: ADJ, Dependency: amod\n",
      "Token: role, POS: NOUN, Dependency: dobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: other, POS: ADJ, Dependency: amod\n",
      "Token: areas, POS: NOUN, Dependency: pobj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: Editors, POS: NOUN, Dependency: dobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: nineteenthcentury, POS: NOUN, Dependency: amod\n",
      "Token: American, POS: ADJ, Dependency: amod\n",
      "Token: authors, POS: NOUN, Dependency: pobj\n",
      "Token: for, POS: ADP, Dependency: prep\n",
      "Token: example, POS: NOUN, Dependency: pobj\n",
      "Token: would, POS: AUX, Dependency: aux\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: also, POS: ADV, Dependency: advmod\n",
      "Token: have, POS: VERB, Dependency: conj\n",
      "Token: to, POS: PART, Dependency: aux\n",
      "Token: call, POS: VERB, Dependency: xcomp\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: recent, POS: ADJ, Dependency: dobj\n",
      "Token: past, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: age, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: Bowers, POS: PROPN, Dependency: pobj\n",
      "Token: as, POS: SCONJ, Dependency: mark\n",
      "Token: would, POS: AUX, Dependency: advcl\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: writers, POS: NOUN, Dependency: nsubj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: descriptive, POS: ADJ, Dependency: amod\n",
      "Token: bibliographies, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: authors, POS: NOUN, Dependency: pobj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: presses, POS: VERB, Dependency: conj\n",
      "Token: His, POS: PRON, Dependency: poss\n",
      "Token: ubiquity, POS: NOUN, Dependency: dobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: broad, POS: ADJ, Dependency: amod\n",
      "Token: field, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: bibliographical, POS: ADJ, Dependency: amod\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: textual, POS: ADJ, Dependency: conj\n",
      "Token: study, POS: VERB, Dependency: pobj\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: seemingly, POS: ADV, Dependency: advmod\n",
      "Token: com, POS: NOUN, Dependency: nmod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: plete, POS: ADJ, Dependency: amod\n",
      "Token: possession, POS: NOUN, Dependency: dobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: it, POS: PRON, Dependency: pobj\n",
      "Token: distinguished, POS: VERB, Dependency: conj\n",
      "Token: him, POS: PRON, Dependency: dobj\n",
      "Token: from, POS: ADP, Dependency: prep\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: illustrious, POS: ADJ, Dependency: amod\n",
      "Token: predeces, POS: NOUN, Dependency: compound\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: sors, POS: NOUN, Dependency: pobj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: made, POS: VERB, Dependency: conj\n",
      "Token: him, POS: PRON, Dependency: nsubj\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: personification, POS: NOUN, Dependency: ccomp\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: bibliographical, POS: ADJ, Dependency: amod\n",
      "Token: scholarship, POS: NOUN, Dependency: pobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: time, POS: NOUN, Dependency: pobj\n",
      "Token: \n",
      "\n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: When, POS: SCONJ, Dependency: advmod\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: 1969, POS: NUM, Dependency: pobj\n",
      "Token: Bowers, POS: PROPN, Dependency: nsubjpass\n",
      "Token: was, POS: AUX, Dependency: auxpass\n",
      "Token: awarded, POS: VERB, Dependency: ccomp\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: Gold, POS: PROPN, Dependency: compound\n",
      "Token: Medal, POS: PROPN, Dependency: nmod\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: Biblio, POS: PROPN, Dependency: compound\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: graphical, POS: ADJ, Dependency: amod\n",
      "Token: Society, POS: PROPN, Dependency: pobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: London, POS: PROPN, Dependency: pobj\n",
      "Token: John, POS: PROPN, Dependency: compound\n",
      "Token: Carters, POS: PROPN, Dependency: compound\n",
      "Token: citation, POS: NOUN, Dependency: nsubj\n",
      "Token: referred, POS: VERB, Dependency: ccomp\n",
      "Token: to, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: Principles, POS: PROPN, Dependency: pobj\n",
      "Token: as, POS: ADV, Dependency: prep\n",
      "Token: majestic, POS: ADJ, Dependency: amod\n",
      "Token: called, POS: VERB, Dependency: acl\n",
      "Token: Bowerss, POS: PROPN, Dependency: nmod\n",
      "Token: current, POS: ADJ, Dependency: amod\n",
      "Token: projects, POS: NOUN, Dependency: oprd\n",
      "Token: formidable, POS: ADJ, Dependency: amod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: said, POS: VERB, Dependency: conj\n",
      "Token: that, POS: SCONJ, Dependency: mark\n",
      "Token: he, POS: PRON, Dependency: nsubj\n",
      "Token: had, POS: AUX, Dependency: aux\n",
      "Token: imposed, POS: VERB, Dependency: ccomp\n",
      "Token: critical, POS: ADJ, Dependency: amod\n",
      "Token: discipline, POS: NOUN, Dependency: dobj\n",
      "Token: on, POS: ADP, Dependency: prep\n",
      "Token: the, POS: DET, Dependency: det\n",
      "Token: texts, POS: NOUN, Dependency: pobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: several, POS: ADJ, Dependency: amod\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: authors, POS: NOUN, Dependency: pobj\n",
      "Token: described, POS: VERB, Dependency: ccomp\n",
      "Token: Studies, POS: PROPN, Dependency: dobj\n",
      "Token: in, POS: ADP, Dependency: prep\n",
      "Token: Bibliography, POS: PROPN, Dependency: pobj\n",
      "Token: as, POS: ADP, Dependency: prep\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: great, POS: ADJ, Dependency: amod\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: continuing, POS: VERB, Dependency: conj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: achievement, POS: NOUN, Dependency: pobj\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: included, POS: VERB, Dependency: conj\n",
      "Token: among, POS: ADP, Dependency: prep\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: characteristics, POS: NOUN, Dependency: pobj\n",
      "Token: uncompromising, POS: VERB, Dependency: xcomp\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: seriousness, POS: NOUN, Dependency: dobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: purpose, POS: NOUN, Dependency: nmod\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: professional, POS: ADJ, Dependency: conj\n",
      "Token: intensity, POS: NOUN, Dependency: pobj\n",
      "Token: Bowers, POS: PROPN, Dependency: nsubj\n",
      "Token: was, POS: AUX, Dependency: conj\n",
      "Token: not, POS: PART, Dependency: neg\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: unaccustomed, POS: ADJ, Dependency: acomp\n",
      "Token: to, POS: ADP, Dependency: prep\n",
      "Token: such, POS: ADJ, Dependency: amod\n",
      "Token: encomia, POS: NOUN, Dependency: pobj\n",
      "Token: but, POS: CCONJ, Dependency: cc\n",
      "Token: he, POS: PRON, Dependency: nsubj\n",
      "Token: had, POS: AUX, Dependency: aux\n",
      "Token: also, POS: ADV, Dependency: advmod\n",
      "Token: experienced, POS: VERB, Dependency: ROOT\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: share, POS: NOUN, Dependency: dobj\n",
      "Token: of, POS: ADP, Dependency: prep\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: attacks, POS: NOUN, Dependency: pobj\n",
      "Token: his, POS: PRON, Dependency: poss\n",
      "Token: scholarly, POS: ADJ, Dependency: amod\n",
      "Token: positions, POS: NOUN, Dependency: pobj\n",
      "Token: were, POS: AUX, Dependency: advcl\n",
      "Token: not, POS: PART, Dependency: neg\n",
      "Token: universally, POS: ADV, Dependency: advmod\n",
      "Token: popular, POS: ADJ, Dependency: acomp\n",
      "Token: and, POS: CCONJ, Dependency: cc\n",
      "Token: he, POS: PRON, Dependency: nsubj\n",
      "Token: \n",
      ", POS: SPACE, Dependency: dep\n",
      "Token: expressed, POS: VERB, Dependency: conj\n",
      "Token: them, POS: PRON, Dependency: dobj\n",
      "Token: with, POS: ADP, Dependency: prep\n",
      "Token: an, POS: DET, Dependency: det\n",
      "Token: aggressiveness, POS: NOUN, Dependency: pobj\n",
      "Token: that, POS: PRON, Dependency: nsubj\n",
      "Token: almost, POS: ADV, Dependency: advmod\n",
      "Token: seemed, POS: VERB, Dependency: relcl\n",
      "Token: calculated, POS: VERB, Dependency: oprd\n",
      "Token: to, POS: ADP, Dependency: prep\n",
      "Token: \n",
      "\n",
      " \n",
      "\f",
      ", POS: SPACE, Dependency: dep\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the clean text\n",
    "doc = nlp(clean_text)\n",
    "\n",
    "# Printing tokens with their pos and dependency\n",
    "for token in doc:\n",
    "  print(f\"Token: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjucerF460gL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
